{"cells":[{"cell_type":"code","execution_count":1,"id":"f9596131","metadata":{},"outputs":[{"data":{"text/plain":["spark = org.apache.spark.sql.SparkSession@2d010f16\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["org.apache.spark.sql.SparkSession@2d010f16"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import org.apache.spark.sql.SparkSession\n","import org.apache.spark.sql.functions._\n","\n","// Step 1: Initialize SparkSession\n","val spark = SparkSession.builder()\n","  .appName(\"User Rating History Partitioning\")\n","  .getOrCreate()"]},{"cell_type":"code","execution_count":2,"id":"29bedcee","metadata":{},"outputs":[{"data":{"text/plain":["ratingsPath = gs://spark_learning_1/notebooks/ratings.csv\n","ratingsDF = [userId: string, movieId: string ... 2 more fields]\n","validRatingsDF = [userId: string, movieId: string ... 2 more fields]\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[userId: string, movieId: string ... 2 more fields]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["val ratingsPath = \"gs://spark_learning_1/notebooks/ratings.csv\"\n","\n","val ratingsDF = spark.read.option(\"header\", \"true\").csv(ratingsPath)\n","\n","// Step 3: Transformation - Filter out invalid or incomplete records\n","val validRatingsDF = ratingsDF\n","  .filter(col(\"userId\").isNotNull && col(\"movieId\").isNotNull && col(\"rating\").isNotNull && col(\"timestamp\").isNotNull)\n"]},{"cell_type":"code","execution_count":5,"id":"f30420d5","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Files saving in-progress ...\n","Files saving completed!\n"]},{"data":{"text/plain":["limitRatingsDF = [userId: string, movieId: string ... 2 more fields]\n","outputPath = hdfs:///user/casestudies/casestudy2\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["hdfs:///user/casestudies/casestudy2"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["val limitRatingsDF = ratingsDF.limit(500000)\n","\n","println(\"Files saving in-progress ...\")\n","\n","// Step 4: Save Data Partitioned by UserId to HDFS\n","val outputPath = \"hdfs:///user/casestudies/casestudy2\"\n","limitRatingsDF.write\n","    .partitionBy(\"userId\")\n","    .format(\"parquet\").mode(\"overwrite\").save(outputPath)\n","\n","println(\"Files saving completed!\")"]},{"cell_type":"code","execution_count":null,"id":"3b5efb2b","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Apache Toree - Scala","language":"scala","name":"apache_toree_scala"},"language_info":{"codemirror_mode":"text/x-scala","file_extension":".scala","mimetype":"text/x-scala","name":"scala","pygments_lexer":"scala","version":"2.12.15"}},"nbformat":4,"nbformat_minor":5}